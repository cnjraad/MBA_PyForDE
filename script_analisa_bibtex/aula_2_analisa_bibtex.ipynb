{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibtex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pymongo import MongoClient\n",
    "import bibtexparser as bp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml as yml\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import sqlite3\n",
    "\n",
    "dir_input = os.path.join(os.getcwd(), 'input')\n",
    "dir_output = os.path.join(os.getcwd(), 'output')\n",
    "dir_config = os.path.join(os.getcwd(), 'config')\n",
    "configFileName = 'config_analisa_bibtex.yml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGA O ARQUIVO DE CONFIGURAÇÃO\n",
    "with open(os.path.join(dir_config, configFileName)) as f:\n",
    "    configFile = yml.load(f, Loader=yml.loader.SafeLoader)\n",
    "\n",
    "# ANALISA BIBTEX\n",
    "listaArquivos = ( \\\n",
    "\tconfigFile['FILE_ACM'], \\\n",
    "\tconfigFile['FILE_IEE'], \\\n",
    "\tconfigFile['FILE_SD' ]\n",
    "\t)\n",
    "\n",
    "def bibtexToDict(arqv):\n",
    "\twith open(os.path.join(dir_input, arqv), encoding='utf8') as f:\n",
    "\t\tbib_database = bp.load(f)\t\t\n",
    "\treturn bib_database.entries_dict.values() # retorna lista de dicionarios\n",
    "\t\n",
    "# UNION DATAFRAMES AND YML\n",
    "listaDf = []\n",
    "listaYml =[]\n",
    "for arqv in listaArquivos:\n",
    "\tsourceArticles = bibtexToDict(arqv)\n",
    "\tlistaDf.append(pd.DataFrame(sourceArticles))\n",
    "\tlistaYml.append(yml.dump(list(sourceArticles)))\n",
    "\n",
    "unionDf = pd.concat(listaDf)\n",
    "unionYml = ''.join(listaYml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported CSV to g:\\Impacta\\GitHub\\MBA_PyForDE\\script_analisa_bibtex\\output\n"
     ]
    }
   ],
   "source": [
    "def df_export(df, file_name, file_format):\n",
    "\tif file_format == 'CSV':\n",
    "\t\tdf.to_csv(os.path.join(dir_output, file_name + '.csv'), sep=';', index=False, encoding='utf-8')\t\t\n",
    "\t\tprint('Exported ' + file_format + ' to ' + dir_output)\n",
    "\telif file_format == 'JSON':\n",
    "\t\tdf.to_json(os.path.join(dir_output, file_name + '.json'), orient = 'records')\n",
    "\t\tprint('Exported ' + file_format + ' to ' + dir_output)\n",
    "\telif file_format == 'YAML':\n",
    "\t\twith open(os.path.join(dir_output, file_name + '.yml'), mode='w',encoding='utf8') as f:\n",
    "\t\t\tf.write(unionYml)\n",
    "\t\t\tprint('Exported ' + file_format + ' to ' + dir_output)\t\n",
    "\telse:\n",
    "\t\tprint('Formato não disponivel.')\n",
    "\n",
    "df_export(unionDf,'ALL_ARTICLES', configFile['FORMATO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saulo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\Users\\Saulo\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "file_scimagojr = 'scimagojr 2020.csv'\n",
    "file_jcs = 'jcs_2020.csv'\n",
    "file_article_impact = 'ALL_Article_Impact.csv'\n",
    "\n",
    "df_scimagojr = pd.read_csv(os.path.join(dir_input, file_scimagojr), delimiter=';', quotechar='\"', header=0)\n",
    "df_jcs = pd.read_csv(os.path.join(dir_input, file_jcs), delimiter=';', quotechar='\"', header=0)\n",
    "\n",
    "# Tratamento\n",
    "dict_treat_data = {'-': np.nan, '': np.nan, None: np.nan, 'Not Available': np.nan}\n",
    "\n",
    "# JCS\n",
    "df_jcs.columns = df_jcs.columns.str.lower()\n",
    "df_jcs.rename(columns ={'journal impact factor':'jcr_value'}, inplace=True)\n",
    "df_jcs.jcr_value.replace(to_replace=dict_treat_data, inplace=True)\n",
    "df_jcs.drop(df_jcs.columns[df_jcs.columns.str.contains('unnamed') == True], axis=1, inplace=True) # Remove colunas vazias no arquivo\n",
    "df_jcs.drop('rank', axis=1, inplace=True)\n",
    "df_jcs.drop_duplicates(inplace=True) # Linha inteira duplicada\n",
    "df_jcs['full journal title'] = df_jcs['full journal title'].str.upper()\n",
    "df_jcs['full journal title'] = df_jcs['full journal title'].str.strip()\n",
    "df_jcs['jcr_value'].loc[df_jcs['jcr_value'].notnull()] = [number.replace(',','.') for number in df_jcs['jcr_value'] if type(number) != float]\n",
    "df_jcs['jcr_value'] = pd.to_numeric(df_jcs['jcr_value'])\n",
    "\n",
    "# SCIMAGO\n",
    "df_scimagojr.columns = df_scimagojr.columns.str.lower()\n",
    "df_scimagojr.rename(columns ={'sjr':'scimago_value'}, inplace=True)\n",
    "df_scimagojr.scimago_value.replace(to_replace=dict_treat_data, inplace=True)\n",
    "df_scimagojr.drop('rank', axis=1, inplace=True)\n",
    "df_scimagojr['title'] = df_scimagojr['title'].str.upper()\n",
    "df_scimagojr['title'] = df_scimagojr['title'].str.strip()\n",
    "df_scimagojr['issn'].replace(to_replace=dict_treat_data, inplace=True)\n",
    "df_scimagojr['scimago_value'].loc[df_scimagojr['scimago_value'].notnull()] = [number.replace(',','.') for number in df_scimagojr['scimago_value'] if type(number) != float]\n",
    "df_scimagojr['scimago_value'] = pd.to_numeric(df_scimagojr['scimago_value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        62.937\n",
       "1        40.949\n",
       "2        37.461\n",
       "3        34.573\n",
       "4        32.011\n",
       "          ...  \n",
       "32599     0.100\n",
       "32600     0.100\n",
       "32601     0.100\n",
       "32602     0.100\n",
       "32603     0.100\n",
       "Name: scimago_value, Length: 32604, dtype: float64"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scimagojr[df_scimagojr['scimago_value'].notnull()]['scimago_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Impact and Bibtex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN SCIMAGO AND BIBTEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bibtex = unionDf.copy()\n",
    "df_bibtex.columns = df_bibtex.columns.str.lower()\n",
    "\n",
    "df_bibtex.issn = df_bibtex.issn.replace(np.nan,'')\n",
    "df_bibtex.issn = list(map(lambda x: x.replace('-',''), df_bibtex.issn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: issn0 shape:(39, 46)\n",
      "Column: issn1 shape:(0, 46)\n",
      "Column: issn2 shape:(0, 46)\n"
     ]
    }
   ],
   "source": [
    "# Trata scimago issn, criando colunas dinamicamente\n",
    "# 00257656, 16993993, 16994019\n",
    "# 19853718, 19858345, 21804249\n",
    "df_treat_scimago_issn = pd.DataFrame([x.split(',') for x in df_scimagojr.issn if type(x) != float])\n",
    "\n",
    "for col in df_treat_scimago_issn.columns:\n",
    "\tcolumn_name = 'issn' + str(col)\n",
    "\tdf_scimagojr.insert(len(df_scimagojr.columns), column_name, df_treat_scimago_issn[col])\n",
    "\n",
    "df_scimagojr.drop(columns='issn', inplace=True)\n",
    "\n",
    "list_issn_col = df_scimagojr.columns[df_scimagojr.columns.str.contains('issn')]\n",
    "list_df_join = []\n",
    "\n",
    "for col_name in list_issn_col:\n",
    "\tdf_join_temp = df_bibtex.merge(df_scimagojr, how='inner', left_on='issn', right_on=col_name, suffixes=['_1','_2']) \n",
    "\tprint('Column: ' + col_name + ' shape:' + str(df_join_temp.shape))\n",
    "\tlist_df_join.append(df_join_temp)\n",
    "\n",
    "df_bibtex_scimagoj = pd.concat(list_df_join)\\\n",
    "\t.drop_duplicates()\\\n",
    "\t\t.dropna(subset=['issn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN JCS AND BIBTEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 29)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bibtex['journal'] = df_bibtex['journal'].str.upper()\n",
    "df_bibtex['journal'] = df_bibtex['journal'].str.strip()\n",
    "\n",
    "df_bibtex_jcs = df_bibtex.merge(df_jcs, how='inner', left_on='journal', right_on='full journal title', suffixes=['_1','_2'])\n",
    "df_bibtex_jcs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN  BIBTEX_SCIMAGOJ AND BIBTEX_JCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN\n",
    "df_bibtex_impact = pd.concat([df_bibtex_scimagoj, df_bibtex_jcs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Big Data', None, None, None, None, None, 2.082, 'CSV')\n"
     ]
    }
   ],
   "source": [
    "# CARREGA O ARQUIVO DE CONFIGURAÇÃO\n",
    "config_file_name = 'config_article_impact.yml'\n",
    "\n",
    "with open(os.path.join(dir_config, config_file_name)) as f:\n",
    "    config_file = yml.load(f, Loader=yml.loader.SafeLoader)\n",
    "\n",
    "filter_list = ( config_file['TITLE'],\\\n",
    "\tconfig_file['KEYWORDS'],\\\n",
    "\tconfig_file['YEAR'],\\\n",
    "\tconfig_file['TYPE_PUBLICATION'],\\\n",
    "\tconfig_file['DOI'],\\\n",
    "\tconfig_file['JCR_VALUE'],\\\n",
    "\tconfig_file['SCIMAGO_VALUE'],\\\n",
    "\tconfig_file['FORMATO']\n",
    "\t)\n",
    "\n",
    "if config_file['JCR_VALUE'] == None:\n",
    "\tconfig_file['JCR_VALUE'] = np.nan\n",
    "\n",
    "if config_file['SCIMAGO_VALUE'] == None:\n",
    "\tconfig_file['SCIMAGO_VALUE'] = np.nan\t\n",
    "\n",
    "print(filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro simultaneo\n",
    "df_filtro_texto = df_bibtex_impact.loc[\n",
    "\t(df_bibtex_impact.title_1.str.contains(\"{}\".format(config_file['TITLE']), case=False)) |\n",
    "\t(df_bibtex_impact.journal.str.contains(\"{}\".format(config_file['TITLE']), case=False)) |\n",
    "\t(df_bibtex_impact.keywords.str.contains(\"{}\".format(config_file['KEYWORDS']), case=False)) |\n",
    "\t(df_bibtex_impact.abstract.str.contains(\"{}\".format(config_file['ABSTRACT']), case=False)) |\n",
    "\t(df_bibtex_impact.year.str.contains(\"{}\".format(config_file['YEAR']), case=False)) |\n",
    "\t(df_bibtex_impact.type.str.contains(\"{}\".format(config_file['TYPE_PUBLICATION']), case=False)) |\n",
    "\t(df_bibtex_impact.doi.str.contains(\"{}\".format(config_file['DOI']), case=False))\n",
    "\t]\n",
    "\n",
    "df_filtro_final = df_filtro_texto.loc[(df_filtro_texto['jcr_value'] == config_file['JCR_VALUE']) |\n",
    "\t(df_filtro_texto['scimago_value'] == config_file['SCIMAGO_VALUE'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_1</th>\n",
       "      <th>journal</th>\n",
       "      <th>jcr_value</th>\n",
       "      <th>scimago_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Data Systems: A Software Engineering Persp...</td>\n",
       "      <td>ACM Comput. Surv.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multimedia Big Data Analytics: A Survey</td>\n",
       "      <td>ACM Comput. Surv.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Survey on IoT Big Data: Current Status, 13 V...</td>\n",
       "      <td>ACM Comput. Surv.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SLA Management for Big Data Analytical Applica...</td>\n",
       "      <td>ACM Comput. Surv.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computational Health Informatics in the Big Da...</td>\n",
       "      <td>ACM Comput. Surv.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_1            journal  \\\n",
       "0  Big Data Systems: A Software Engineering Persp...  ACM Comput. Surv.   \n",
       "1            Multimedia Big Data Analytics: A Survey  ACM Comput. Surv.   \n",
       "2  A Survey on IoT Big Data: Current Status, 13 V...  ACM Comput. Surv.   \n",
       "3  SLA Management for Big Data Analytical Applica...  ACM Comput. Surv.   \n",
       "4  Computational Health Informatics in the Big Da...  ACM Comput. Surv.   \n",
       "\n",
       "   jcr_value  scimago_value  \n",
       "0        NaN          2.082  \n",
       "1        NaN          2.082  \n",
       "2        NaN          2.082  \n",
       "3        NaN          2.082  \n",
       "4        NaN          2.082  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtro_final[['title_1','journal','jcr_value','scimago_value']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported CSV to g:\\Impacta\\GitHub\\MBA_PyForDE\\script_analisa_bibtex\\output\n"
     ]
    }
   ],
   "source": [
    "df_export(df_filtro_final,'bibtex_impact',config_file['FORMATO'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INSERE DADOS NO BANCO\n",
    "# client = MongoClient(\"localhost\", 27017)\n",
    "# \n",
    "# db = client.Projeto\n",
    "# db.projeto.insert_many(df_filtro_final.to_dict('records'))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dd43a9e67059d268b0a6eaf9f3d73cd4', 'zcw5heuva2mrz4an52gf32y6', \"/'data quality' AND 'big data'\", 'JSON')\n"
     ]
    }
   ],
   "source": [
    "# CARREGA O ARQUIVO DE CONFIGURAÇÃO\n",
    "config_file_name = 'config_api.yml'\n",
    "\n",
    "with open(os.path.join(dir_config, config_file_name)) as f:\n",
    "    config_file = yml.load(f, Loader=yml.loader.SafeLoader)\n",
    "\n",
    "url_config = ( config_file['API_TOKEN_SCOPUS'],\\\n",
    "\tconfig_file['API_TOKEN_IEEE'],\\\n",
    "\tconfig_file['API_STRING'],\\\n",
    "\tconfig_file['FORMATO']\n",
    "\t)\n",
    "\n",
    "print(url_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# url = 'https://ieeexploreapi.ieee.org/api/v1/search/articles?apikey=zcw5heuva2mrz4an52gf32y6&querytext='+config_file['API_STRING']\n",
    "# url_scopus = 'http://api.elsevier.com/content/search/scopus?query='+config_file['API_STRING']+'&apiKey=dd43a9e67059d268b0a6eaf9f3d73cd4'\n",
    "# ##var_union = []\n",
    "# \n",
    "# resposta_hoteis = requests.request('GET', url)\n",
    "# resposta_scopus = requests.request('GET', url_scopus)\n",
    "# var_teste = resposta_hoteis.json()\n",
    "# var_teste_scopus = resposta_scopus.json()\n",
    "# var_teste.items()\n",
    "# var_teste_scopus.items()\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consuming API IEEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta_data='WMATA'\n",
    "max_records=7\n",
    "\n",
    "requestsIEEE = requests.get(f'http://ieeexploreapi.ieee.org/api/v1/search/articles?apikey=zcw5heuva2mrz4an52gf32y6&format=json&max_records={max_records}&start_record=1&sort_order=asc&sort_field=article_number&\\\n",
    "\tmeta_data={meta_data}')\n",
    "\n",
    "# Verificar se requestsIEEE.ok\n",
    "\n",
    "#df = pd.json_normalize(json_teste,record_path=[\"articles\"])\n",
    "dict = json.loads(requestsIEEE.text)\n",
    "df_api_articles = pd.DataFrame.from_dict(dict['articles'])\n",
    "\n",
    "df_api_articles = df_api_articles[['title', 'abstract', 'publication_year', 'authors', 'doi', 'content_type', 'issn', 'isbn']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento API IEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    J.-M. Shyu/A. Sangiovanni-Vincentelli/J.P. Fis...\n",
       "1                    R. Bisiani/F. Lecouat/V. Ambriola\n",
       "2               J.K. Parker/A.R. Khoogar/D.E. Goldberg\n",
       "3                                            M. Hosang\n",
       "4                Hyun Mun Kim/Hyung-Suk Kim/T. Acharya\n",
       "5                                        A. Krivoulets\n",
       "6                                           G. Lakhani\n",
       "Name: authors, dtype: object"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_authors=[]\n",
    "\n",
    "# Trata autores, dicionario com listas aninhadas\n",
    "for count_articles, value in enumerate(df_api_articles['authors']):\n",
    "\tlist_authors.append([dict['full_name'] for dict in df_api_articles['authors'][count_articles]['authors']])\n",
    "\tlist_authors[count_articles] = '/'.join(list_authors[count_articles]) \n",
    "\n",
    "df_api_articles['authors'] = list_authors\n",
    "df_api_articles['authors'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saulo\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# ISSN com '-'\n",
    "issn_treated = [issn.replace('-', '') for issn in df_api_articles['issn'] if type(issn) == str]\n",
    "df_api_articles['issn'].loc[df_api_articles['issn'].notna()] = issn_treated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN API IEEE AND SCIMAGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: issn0 shape:(5, 29)\n",
      "Column: issn1 shape:(0, 29)\n",
      "Column: issn2 shape:(0, 29)\n"
     ]
    }
   ],
   "source": [
    "# Trata scimago issn, criando colunas dinamicamente\n",
    "# 00257656, 16993993, 16994019\n",
    "# 19853718, 19858345, 21804249\n",
    "list_issn_col = df_scimagojr.columns[df_scimagojr.columns.str.contains('issn')]\n",
    "list_df_join = []\n",
    "\n",
    "for col_name in list_issn_col:\n",
    "\tdf_join_temp = df_api_articles.merge(df_scimagojr, how='inner', left_on='issn', right_on=col_name, suffixes=[None,'_2'])\\\n",
    "\t\t.dropna(subset=['issn'])\t\n",
    "\tprint('Column: ' + col_name + ' shape:' + str(df_join_temp.shape))\n",
    "\tlist_df_join.append(df_join_temp)\n",
    "\n",
    "df_api_articles_scimagoj = pd.concat(list_df_join).drop_duplicates()\n",
    "\n",
    "df_api_articles_scimagoj = df_api_articles_scimagoj[['title', 'abstract', 'publication_year', 'authors', 'doi',\\\n",
    "\t 'content_type', 'issn', 'isbn','scimago_value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN API IEEE AND JCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### JOIN API IEEE AND JCS\n",
    "\n",
    "df_api_articles['title'] = df_api_articles['title'].str.upper()\n",
    "df_api_articles['title'] = df_api_articles['title'].str.strip()\n",
    "\n",
    "df_api_articles_jcs = df_api_articles.merge(df_jcs, how='inner', left_on='title', right_on='full journal title', suffixes=[None,'_2'])\n",
    "df_api_articles_jcs = df_api_articles_jcs[['title', 'abstract', 'publication_year', 'authors', 'doi',\\\n",
    "\t 'content_type', 'issn', 'isbn','jcr_value']]\n",
    "\n",
    "df_api_articles_jcs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN API IEEE AND SCIMAGO AND JCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>authors</th>\n",
       "      <th>doi</th>\n",
       "      <th>content_type</th>\n",
       "      <th>issn</th>\n",
       "      <th>isbn</th>\n",
       "      <th>scimago_value</th>\n",
       "      <th>jcr_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optimization-based transistor sizing</td>\n",
       "      <td>A combined heuristic and mathematical programm...</td>\n",
       "      <td>1988</td>\n",
       "      <td>J.-M. Shyu/A. Sangiovanni-Vincentelli/J.P. Fis...</td>\n",
       "      <td>10.1109/4.1000</td>\n",
       "      <td>Journals</td>\n",
       "      <td>1558173X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.576</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>A character elimination algorithm for lossless...</td>\n",
       "      <td>Summary form only given. We present a detailed...</td>\n",
       "      <td>2002</td>\n",
       "      <td>M. Hosang</td>\n",
       "      <td>10.1109/DCC.2002.1000000</td>\n",
       "      <td>Conferences</td>\n",
       "      <td>10680314</td>\n",
       "      <td>0-7695-1477-4</td>\n",
       "      <td>0.325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>Rate control using conditional mean estimator</td>\n",
       "      <td>Summary form only given. This paper presents a...</td>\n",
       "      <td>2002</td>\n",
       "      <td>Hyun Mun Kim/Hyung-Suk Kim/T. Acharya</td>\n",
       "      <td>10.1109/DCC.2002.1000001</td>\n",
       "      <td>Conferences</td>\n",
       "      <td>10680314</td>\n",
       "      <td>0-7695-1477-4</td>\n",
       "      <td>0.325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>On coding of sources with two-sided geometric ...</td>\n",
       "      <td>Summary form only given. We address the proble...</td>\n",
       "      <td>2002</td>\n",
       "      <td>A. Krivoulets</td>\n",
       "      <td>10.1109/DCC.2002.1000002</td>\n",
       "      <td>Conferences</td>\n",
       "      <td>10680314</td>\n",
       "      <td>0-7695-1477-4</td>\n",
       "      <td>0.325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>Using multiple Huffman code tables for optimal...</td>\n",
       "      <td>Summary form only given. It is a well-known ob...</td>\n",
       "      <td>2002</td>\n",
       "      <td>G. Lakhani</td>\n",
       "      <td>10.1109/DCC.2002.1000003</td>\n",
       "      <td>Conferences</td>\n",
       "      <td>10680314</td>\n",
       "      <td>0-7695-1477-4</td>\n",
       "      <td>0.325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                  Optimization-based transistor sizing   \n",
       "6274  A character elimination algorithm for lossless...   \n",
       "6275      Rate control using conditional mean estimator   \n",
       "6276  On coding of sources with two-sided geometric ...   \n",
       "6277  Using multiple Huffman code tables for optimal...   \n",
       "\n",
       "                                               abstract  publication_year  \\\n",
       "0     A combined heuristic and mathematical programm...              1988   \n",
       "6274  Summary form only given. We present a detailed...              2002   \n",
       "6275  Summary form only given. This paper presents a...              2002   \n",
       "6276  Summary form only given. We address the proble...              2002   \n",
       "6277  Summary form only given. It is a well-known ob...              2002   \n",
       "\n",
       "                                                authors  \\\n",
       "0     J.-M. Shyu/A. Sangiovanni-Vincentelli/J.P. Fis...   \n",
       "6274                                          M. Hosang   \n",
       "6275              Hyun Mun Kim/Hyung-Suk Kim/T. Acharya   \n",
       "6276                                      A. Krivoulets   \n",
       "6277                                         G. Lakhani   \n",
       "\n",
       "                           doi content_type      issn           isbn  \\\n",
       "0               10.1109/4.1000     Journals  1558173X            NaN   \n",
       "6274  10.1109/DCC.2002.1000000  Conferences  10680314  0-7695-1477-4   \n",
       "6275  10.1109/DCC.2002.1000001  Conferences  10680314  0-7695-1477-4   \n",
       "6276  10.1109/DCC.2002.1000002  Conferences  10680314  0-7695-1477-4   \n",
       "6277  10.1109/DCC.2002.1000003  Conferences  10680314  0-7695-1477-4   \n",
       "\n",
       "      scimago_value  jcr_value  \n",
       "0             2.576        NaN  \n",
       "6274          0.325        NaN  \n",
       "6275          0.325        NaN  \n",
       "6276          0.325        NaN  \n",
       "6277          0.325        NaN  "
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_articles_final = pd.concat([df_api_articles_scimagoj, df_api_articles_jcs])\n",
    "df_api_articles_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None,\n",
       "  'A combined heuristic and mathematical programming approach to transistor sizing is presented. A fast heuristic algorithm is used to obtain an initial sizing of the circuit and convert the transistor sizing problem into a nonlinear optimization problem. The problem is then solved, in spaces of reduced dimensionality, by mathematical programming techniques. To cope with the nondifferentiability of the circuit delays, the concept of generalized gradients is proposed to compute the delay sensitivities. Experiments justify the use of this sensitivity computation technique and show that the approach is a good compromise between the speed of the heuristic algorithm and the power of mathematical programming.&lt;<ETX>&gt;</ETX>',\n",
       "  'J.-M. Shyu/A. Sangiovanni-Vincentelli/J.P. Fishburn/A.E. Dunlop',\n",
       "  'Journals',\n",
       "  '10.1109/4.1000',\n",
       "  None,\n",
       "  '1558173X',\n",
       "  1988.0,\n",
       "  2.576,\n",
       "  'Optimization-based transistor sizing'),\n",
       " (None,\n",
       "  'Summary form only given. We present a detailed description of a lossless compression algorithm intended for use on files with non-uniform character distributions. This algorithm takes advantage of the relatively small distances between character occurrences once we remove the less frequent characters. This allows it to create a compressed version of the file that, when decompressed, is an exact copy of the file that was compressed. We begin by performing a Burrows-Wheeler (1994) Transform (BWT) on the file. The algorithm scans this BWT file to create a character frequency model for the compression phase. To deal with the issue of bit encoding, we write every number as a byte or sequence of bytes to the compressed file and run an arithmetic encoder after the file has been compiled.',\n",
       "  'M. Hosang',\n",
       "  'Conferences',\n",
       "  '10.1109/DCC.2002.1000000',\n",
       "  '0-7695-1477-4',\n",
       "  '10680314',\n",
       "  2002.0,\n",
       "  0.325,\n",
       "  'A character elimination algorithm for lossless data compression'),\n",
       " (None,\n",
       "  \"Summary form only given. This paper presents a simple, fast and accurate rate control algorithm using conditional mean estimator (nonlinear regression) that plays a central role in estimation theory. Central to nonlinear estimation and stochastic control problems is the determination of the probability density function of the state conditioned on the available data. If this a posteriori density function is known, then an estimate of the state for any performance can be determined. The proposed algorithm measures this conditional mean by estimating a joint probability density function (PDF) using Parzen's window by extending it to multivariate case. We use this window function to estimate a joint PDF using long training data. The training data pick up the joint PDF between the quantization parameter (QP) and the bits spent for each macroblock depending on the sum of absolute differences (SAD) value from motion estimation. Since the SAD information is obtained as by-product of motion estimation, the additional complexity is minimal. We increase the accuracy of this joint PDF by clustering the training data depending on the QP values within admissible ranges. This localization helps understand image characteristics more accurately. Then we apply the adaptive vector quantization to simplify the conditional mean estimation of the rate given the SAD and QP values. This information is stored into three look-up tables for I, P and B pictures. They contain the localized R-D function on macroblock basis. We use these tables to find the optimal QP values in least-mean-square (LMS) sense for a given bit budget of the current frame. We compared our proposed algorithm with the MPEG-4-rate control algorithm (Q2). Simulation results show that the proposed algorithm outperforms the informative MPEG-4 rate control algorithm in terms of reproduced image quality and coding efficiency while requiring much less implementation complexity.\",\n",
       "  'Hyun Mun Kim/Hyung-Suk Kim/T. Acharya',\n",
       "  'Conferences',\n",
       "  '10.1109/DCC.2002.1000001',\n",
       "  '0-7695-1477-4',\n",
       "  '10680314',\n",
       "  2002.0,\n",
       "  0.325,\n",
       "  'Rate control using conditional mean estimator'),\n",
       " (None,\n",
       "  'Summary form only given. We address the problem of entropy coding of integers i/spl isin/Z with a probability distribution defined as the two-sided geometric distribution (TSGD) which arises mainly in tasks of image and video compression. An efficient method based on binary tree decomposition of the source alphabet, combined with binary arithmetic coding, was proposed for coding of DC and AC coefficients of the DCT in the JPEG image compression standard. Binary decomposition allows for efficient coding of sources with large alphabets and skewed distribution. We propose two binary decompositions for coding of sources with the TSGD.',\n",
       "  'A. Krivoulets',\n",
       "  'Conferences',\n",
       "  '10.1109/DCC.2002.1000002',\n",
       "  '0-7695-1477-4',\n",
       "  '10680314',\n",
       "  2002.0,\n",
       "  0.325,\n",
       "  'On coding of sources with two-sided geometric distribution using binary decomposition'),\n",
       " (None,\n",
       "  'Summary form only given. It is a well-known observation that when a DCT block is traversed in a zig-zag order, the AC coefficients generally decrease in size and the run-length of zero coefficients increase in number. Therefore, use of a single AC Huffman code table in the JPEG baseline algorithm leads to sub-optimal coding, and it is desirable to use multiple code tables, one for each DCT coefficient position, if necessary. It creates a problem, because a nonzero coefficient, X, and the run-length, Z, of zero coefficients that precede X, are coded as one element (Z,X), and therefore, the decoder may not know which table to use to decode the next X. To solve this problem, we made a minor modification to the JPEG Huffman coding algorithm. To evaluate reduction in the code size using our method, we compressed the luminancec component of ten well-known test images at default quality level and computed AC Huffman code size.',\n",
       "  'G. Lakhani',\n",
       "  'Conferences',\n",
       "  '10.1109/DCC.2002.1000003',\n",
       "  '0-7695-1477-4',\n",
       "  '10680314',\n",
       "  2002.0,\n",
       "  0.325,\n",
       "  'Using multiple Huffman code tables for optimal coding of DCT blocks')]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(':memory:')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''CREATE TABLE tb_articles\n",
    "                (title             text\n",
    "                ,abstract          text\n",
    "                ,publication_year  integer\n",
    "                ,authors           text\n",
    "                ,doi               text\n",
    "                ,content_type      text\n",
    "                ,issn              text\n",
    "                ,isbn              text)              \n",
    "            ''')\n",
    "\n",
    "df_api_articles_final.to_sql('tb_articles', conn, if_exists='replace', index = False)\n",
    "\n",
    "cur.execute('SELECT * FROM tb_articles')\n",
    "\n",
    "[row for row in cur.fetchall()]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c88cb824a805180d817a96a07b20374513adbd46c79f5fbf9d369ad17daacecf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
